# Rock, Paper & Scissor Recognition

Based on the code from [Keith Galli](https://github.com/KeithGalli), I just
tweak the DNN a little more to get better performance.

In this example, 3 architectures were tested. Finally, a 4th one is created
using the keras tuner library, I play around with number of Convolution layers,
kernel sizes, neurons of Dense layers and learning rate from the Adam optimizer.

This example can be improved with more keras tuner tests, or some data
augmentation techniques.
